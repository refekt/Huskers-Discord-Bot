import discord
import function_helper
import requests
import json
import datetime
import pandas
import crystal_balls
import os, sys, inspect
# import importlib
from bs4 import BeautifulSoup
import re
from discord.ext import commands
import mysql

currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
parrentdir = os.path.dirname(currentdir)
sys.path.insert(0, parrentdir)
import config

wrong_channel_text='The command you sent is not authorized for use in this channel.'
welcome_footer='HusekrBot welcomes you!'
huskerbot_footer="Generated by HuskerBot"

authorized_to_quit = [440639061191950336, 443805741111836693, 189554873778307073, 339903241204793344, 606301197426753536]
emoji_list = ['1âƒ£', '2âƒ£', '3âƒ£', '4âƒ£', '5âƒ£', '6âƒ£', '7âƒ£', '8âƒ£', '9âƒ£', 'ðŸ”Ÿ']
long_positions = {'PRO' : 'Pro-Style Quarterback',
                  'DUAL': 'Dual-Threat Quarterback',
                  'APB' : 'All-Purpose Back',
                  'RB' : 'Running Back',
                  'FB' : 'Fullback',
                  'WR' : 'Wide Receiver',
                  'TE' : 'Tight End',
                  'OT' : 'Offensive Tackle',
                  'OG' : 'Offensive Guard',
                  'OC' : 'Center',
                  'SDE' : 'Strong-Side Defensive End',
                  'WDE' : 'Weak-Side Defensive End',
                  'DT' : 'Defensive Tackle',
                  'ILB' : 'Inside Linebacker',
                  'OLB' : 'Outside Linebacker',
                  'CB' : 'Cornerback',
                  'S' : 'Safety',
                  'ATH' : 'Athlete',
                  'K' : 'Kicker',
                  'P' : 'Punter',
                  'LS' : 'Long Snapper',
                  'RET' : 'Returner'
                  }
globalRate = 3
globalPer = 30

try:
    with open('team_ids.json', 'r') as fp:
        team_ids = json.load(fp)
except:
    print("Error opening team_ids.json")


class Recruit():
    def __init__(self, name, metrics, position, hometown, image, rating, commit_dt, profile, school="", stars=None, transfer=False, transfer_eligibility="", transfer_location="N/A"):
        self.name = name
        self.metrics = metrics
        self.position = position
        self.hometown = hometown
        self.image = image
        self.school = school
        self.stars = stars
        self.rating = rating
        self.commit_dt = commit_dt
        self.profile = profile
        self.transfer = transfer
        self.transfer_eligibility = transfer_eligibility
        self.transfer_location = transfer_location
        if not transfer:
            self.recruit_string = \
                f"{stars} â­ {name} ({hometown}) | {position} | {metrics} lbs"
        else:
            self.recruit_string = \
                f"{stars} â­ {name} ({transfer_location}) | {position} | {metrics} lbs"


def last_run():
    with mysql.sqlConnection.cursor() as cursor:
        cursor.execute(config.sqlRetrieveCrystalBallLastRun)
    mysql.sqlConnection.commit()
    last_run = cursor.fetchone()
    cursor.close()

    return last_run


def sports_embed(*fields):
    embed = discord.Embed(title="Huskers 247Sports", description="Nebraska Huskers Football and Recruiting", color=0xFF0000)
    embed.set_footer(text="Frost Bot")
    embed.set_thumbnail(url="https://s3media.247sports.com/Uploads/Assets/247/264/8264247.png")
    embed.set_author(name="Bot Frost", url="https://reddit.com/u/Bot_Frost", icon_url="https://i.imgur.com/Ah3x5NA.png")
    for field in fields:
        embed.add_field(name=field[0], value=field[1], inline=False)
    return embed


# TODO Look at and revamp
async def check_last_run():
    """ Check when the last time the JSON was pulled. """
    now = datetime.datetime.now()
    temp_check = last_run()
    check = pandas.to_datetime(temp_check) + datetime.timedelta(minutes=crystal_balls.CB_REFRESH_INTERVAL)

    print("***\nNow: {}\nTemp Check: {}\nCheck: {}\nNow > Check: {}\n***".format(now, temp_check, check, now > check))

    if now > check:
        print("Last time the JSON was pulled exceeded threshold")

        crystal_balls.move_cb_to_list_and_json(json_dump=True)

        with mysql.sqlConnection.cursor() as cursor:
            cursor.execute(config.sqlUpdateCrystalLastRun, (datetime.datetime.now()))
        mysql.sqlConnection.commit()
        cursor.close()
    else:
        if len(crystal_balls.cb_list) <= 1:
            crystal_balls.load_cb_to_list()


async def parse_search(search, channel):
    year = search['Year']
    player = search['Player']
    first_name = player['FirstName']
    last_name = player['LastName']
    position = player['PrimaryPlayerPosition']['Abbreviation']
    if position in long_positions:
        position = long_positions[position]
    hometown = player['Hometown']
    state = hometown['State']
    city = hometown['City']
    height = player['Height'].replace('-', "'") + '"'
    weight = player['Weight']
    high_school = player['PlayerHighSchool']['Name']
    image_url = player['DefaultAssetUrl']
    composite_rating = player['CompositeRating']
    if composite_rating is None:
        composite_rating = 'N/A'
    else:
        composite_rating = player['CompositeRating'] / 100
    composite_star_rating = player['CompositeStarRating']
    national_rank = player['NationalRank']
    if national_rank is None:
        national_rank = 'N/A'
    position_rank = player['PositionRank']
    if position_rank is None:
        position_rank = 'N/A'
    state_rank = player['StateRank']
    if state_rank is None:
        state_rank = 'N/A'
    player_url = player['Url']
    # global profile_url
    config.profile_url = player_url

    # Grab the croot's Twitter handle from their player_url page
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'}
    page = None
    try:
        page = requests.get(url=player_url, headers=headers)
    except requests.exceptions.RequestException as e:
        print(e)

    soup = BeautifulSoup(page.text, 'html.parser')
    re_pattern = "data-username=\".{0,}?\""
    twitter_raw = soup.find_all('div', class_='main-div clearfix')
    if twitter_raw:
        twitter_raw = str(twitter_raw[0])
        twitter_raw2 = re.findall(re_pattern, twitter_raw)
        if len(twitter_raw2) > 0:
            twitter_handle = twitter_raw2[0]
            twitter_handle = twitter_handle.replace("@","")
            twitter_handle = twitter_handle[15:-1]
            twitter_url = "https://twitter.com/" + twitter_handle
        else:
            twitter_handle = "N/A"
            twitter_url = ""
    else:
        twitter_handle = "Unable to locate"
        twitter_url = ""
        print("really not sure")
    # Attempting to get twitter handle from player_url

    stars = ''
    for i in range(int(composite_star_rating)):
        stars += '\N{WHITE MEDIUM STAR}'

    # Check if they are committed. It's a little different with signed players.
    commit_status = search['HighestRecruitInterestEventType']
    if commit_status == 'HardCommit' or commit_status == 'SoftCommit':
        commit_status = 'Committed'
    else:
        commit_status = 'Uncommitted'
    if type(search['SignedInstitution']) is int:
        commit_status = 'Signed'
    title = '{} **{} {}, {} {}**'.format(stars, first_name, last_name, year, position)

    # Now that composite rating can be str or float, we need to handle both cases. Also, don't want the pound sign in front of N/A values.
    if type(composite_rating) is str:
        body = '**Player Bio**\nHome Town: {}, {}\nHigh School: {}\nHeight: {}\nWeight: {}\n\n**247Sports Info**\nComposite Rating: {}\nProfiles: [Click Me]({})\n\n**Twitter**\n[@{}]({})\n\n'.format(city, state, high_school, height, int(weight), composite_rating, player_url, twitter_handle, twitter_url)
        rankings = '**Rankings**\nNational: #{}\nState: #{}\nPosition: #{}\n'.format(national_rank, state_rank, position_rank)
    else:
        body = '**Player Bio**\nHome Town: {}, {}\nHigh School: {}\nHeight: {}\nWeight: {}\n\n**247Sports Info**\nComposite Rating: {:.4f}\nProfile: [Click Me]({})\n\n**Twitter**\n[@{}]({})\n\n'.format(city, state, high_school, height, int(weight), composite_rating, player_url, twitter_handle, twitter_url)
        rankings = '**Rankings**\nNational: #{}\nState: #{}\nPosition: #{}\n'.format(national_rank, state_rank, position_rank)

    # Create a recruitment status string. If they are committed, use our scraped json team_ids dictionary to get the team name from the id in the committed team image url.
    # I've found that if a team does not have an image on 247, they use a generic image with 0 as the id. Also if the image id is not in the dictionary, we want to say Unknown.
    recruitment_status = 'Currently {}'.format(commit_status)
    if commit_status == 'Committed' or commit_status == 'Signed':
        school_id = str(search['CommitedInstitutionTeamImage'].split('/')[-1].split('.')[0])
        if school_id == '0' or school_id not in team_ids:
            school = 'Unknown'
        else:
            school = team_ids[school_id]
        if school == 'Nebraska':
            school += ' ðŸ’¯:corn::punch:'
        recruitment_status += ' to {}'.format(school)
    recruitment_status = '**' + recruitment_status + '**\n\n'

    crootstring = recruitment_status + body + rankings
    message_embed = discord.Embed(name="CrootBot", color=0xd00000)
    message_embed.add_field(name=title, value=crootstring, inline=False)
    # Don't want to try to set a thumbnail for a croot who has no image on 247
    if image_url != '/.':
        message_embed.set_thumbnail(url=image_url)
    message_embed.set_footer(text=huskerbot_footer)
    await channel.send(embed=message_embed)

    #global player_search_list
    config.player_search_list = []


class CrootBot(commands.Cog, name="Croot Bot"):
    def __init__(self, bot):
        self.bot = bot

    @commands.group(name="247")
    async def _247(self, ctx):
        if not ctx.subcommand_passed:
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'}
            page = None
            try:
                page = requests.get(url="https://247sports.com/college/nebraska/", headers=headers)
            except:
                print("Error getting 247sports homepage")
                return

            soup = BeautifulSoup(page.text, "html.parser")
            temp_articles = soup.find_all(class_="news-article__img")
            articles = ""

            for index, art in enumerate(temp_articles):
                href = art.attrs["href"]
                for child in art.children:
                    try:
                        title = child.contents[0].attrs["title"]
                    except IndexError:
                        continue
                    except:
                        continue

                    url = f"[{title}]({href})"
                    articles += f"{url}\n"

                if index >= 4:
                    break

            await ctx.send(
                embed=sports_embed(
                    ["Home Page", "https://247sports.com/college/nebraska/"],
                    ["Recent News", articles[0:1023]]
                )
            )

    @_247.command()
    async def commits(self, ctx):
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'}
        page = None
        try:
            page = requests.get(url="https://247sports.com/college/nebraska/Season/2020-Football/Commits/", headers=headers)
        except:
            print("Error getting 247sports homepage")
            return

        soup = BeautifulSoup(page.text, "html.parser")

        ranks_rating = soup.find_all(class_="ir-bar__number")
        r_r = []
        for r in ranks_rating:
            r_r.append(r.contents[0])
        ranks_rating_string = f"National Rank: {r_r[0]}\n" \
                              f"Big-Ten Rank: {r_r[1]}\n" \
                              f"Avg. Rating: {r_r[2]}"

        recruits = []

        commits_list = soup.find_all(class_="ri-page__list-item")
        for index, commit in enumerate(commits_list):
            if index > 0:
                for child in commit.children:
                    if len(child) > 1:
                        image = child.contents[1].contents[1].attrs["data-src"]
                        name = child.contents[3].contents[1].contents[0]
                        href = child.contents[3].contents[1].attrs["href"].split("//")[1]
                        metrics = child.contents[5].contents[0]
                        stars = 0
                        for star_check in child.contents[7].contents[1].contents:
                            if str(star_check) == "<span class=\"icon-starsolid yellow\"></span>":
                                stars += 1
                        rating = child.contents[7].contents[1].contents[7].contents[0]
                        commit_date = child.contents[9].contents[1].contents[0].split(" ")[2]
                        position = child.contents[11].contents[0]
                        school_hometown = child.contents[1].parent.contents[3].contents[3].contents[0]
                        school = school_hometown.split("(")[0].strip()
                        hometown = school_hometown.split("(")[1].split(")")[0]

                        recruits.append(
                            Recruit(
                                name=name,
                                metrics=metrics,
                                position=position,
                                hometown=hometown,
                                school=school,
                                image=image,
                                stars=stars,
                                rating=rating,
                                commit_dt=commit_date,
                                profile=f"https://{href}",
                                transfer=False,
                                transfer_eligibility="",
                                transfer_location=""
                            )
                        )

        transfers_list = soup.find_all(class_="portal-list_itm")
        for index, transfer in enumerate(transfers_list):
            if index > 0:
                image = transfer.contents[1].contents[1].attrs["data-src"].split("?")[0]
                name = transfer.contents[3].contents[1].contents[0]
                href = transfer.contents[3].contents[1].attrs["href"]
                metrics = transfer.contents[5].contents[0]
                stars = 0
                for star_check in transfer.contents[7].contents[1].contents:
                    if str(star_check) == "<span class=\"icon-starsolid yellow\"></span>":
                        stars += 1
                rating = transfer.contents[7].contents[1].contents[7].contents[0]
                eligibility = transfer.contents[9].contents[0]
                position = transfer.contents[11].contents[0]
                xfer_loc = \
                    f"{transfer.contents[13].contents[1].contents[0].attrs['alt']}" \
                    f"Â»" \
                    f"{transfer.contents[13].contents[5].contents[0].attrs['alt']}"

                print(f"[{xfer_loc}]")
                if xfer_loc == "":
                    xfer_loc = "N/A"

                recruits.append(
                    Recruit(
                        name=name,
                        metrics=metrics,
                        position=position,
                        hometown="",
                        school="",
                        image=image,
                        stars=stars,
                        rating=rating,
                        commit_dt="",
                        profile=f"https://{href}",
                        transfer=True,
                        transfer_eligibility=eligibility,
                        transfer_location=xfer_loc
                    )
                )

        recruit_string = ""
        for recruit in recruits:
            recruit_string += f"{recruit.recruit_string}\n"

        await ctx.send(
            embed=sports_embed(
                ["Recruiting Home Page", "[https://247sports.com/college/nebraska/Season/2020-Football/Commits/](Click)"],
                ["Recruiting Rankings", ranks_rating_string],
                ["Total Number of Recruits", len(recruits)],
                ["Recruits", recruit_string[0:1023]]
            )
        )

    @commands.command(hidden=True, aliases=["cbr", ])
    @commands.has_any_role(606301197426753536, 440639061191950336, 443805741111836693)
    @commands.cooldown(rate=globalRate, per=globalPer, type=commands.BucketType.user)
    async def cb_refresh(self, ctx):
        """ Did HuskerBot act up? Use this only in emergencies. """
        await check_last_run()

    @commands.command(aliases=["rb", ])
    @commands.cooldown(rate=globalRate, per=globalPer, type=commands.BucketType.user)
    async def recentballs(self, ctx, number=0):
        """ Send the last 1-5 crystal ball predictions from Steve Wiltfong. Usage is `$recent_balls [1-5]`. """
        # Error handling, Random number of 5 to prevent spam

        # This keeps bot spam down to a minimal.
        await function_helper.check_command_channel(ctx.command, ctx.channel)
        if not function_helper.correct_channel:
            await ctx.send(wrong_channel_text)
            return

        if number > 5:  # len(crystal_balls.cb_list):
            await ctx.send("The number of retrieved Crystal Balls must be less than 5.")
            return

        if not crystal_balls.cb_list:
            crystal_balls.load_cb_to_list()

        limitSpam = -1

        if number > 0:
            number -= 1

        for cbs in crystal_balls.cb_list:
            if limitSpam >= number:
                return

            varPhoto = cbs['Photo']
            varName = cbs['Name']
            varPrediction = cbs['Prediction']
            varPredictionDate = cbs['PredictionDate']
            varProfile = "[Profile]({})".format(cbs['Profile'])
            varResult = cbs['Result']
            varTeams = dict(cbs['Teams'])
            varTeamString = ""

            for x, y in varTeams.items():
                varTeamString += '{} : {}\n'.format(x, y)

            embed = discord.Embed(title="Steve Wiltfong Crystal Ball Predictions", color=0xff0000)
            embed.set_thumbnail(url=varPhoto)
            embed.add_field(name="Player Name", value=varName, inline=False)
            embed.add_field(name="Prediction", value=varPrediction, inline=True)
            embed.add_field(name="Prediction Date/Time", value=varPredictionDate, inline=True)
            embed.add_field(name="Result", value=varResult, inline=False)
            embed.add_field(name="Predicted Teams", value=varTeamString, inline=True)
            embed.add_field(name="247Sports Profile", value=varProfile, inline=False)
            embed.set_footer(text="Recent Crystal Balls" + huskerbot_footer)
            await ctx.send(embed=embed)

            limitSpam += 1

    # TODO Add error handling for `team` to be missing.
    @commands.command()
    @commands.cooldown(rate=globalRate, per=globalPer, type=commands.BucketType.user)
    async def cb_search(self, ctx, *, team):
        """ Search through all of Steve Wiltfong's crystal ball predictions by team. """

        # This keeps bot spam down to a minimal.
        await function_helper.check_command_channel(ctx.command, ctx.channel)
        if not function_helper.correct_channel:
            await ctx.send(wrong_channel_text)
            return

        if not crystal_balls.cb_list:
            crystal_balls.load_cb_to_list()

        search_list = crystal_balls.cb_list
        saved_results = []

        for key in search_list:
            first_name = key['Name']
            prediction = key['Prediction']
            predictiondate = key['PredictionDate']
            # profile = key['Profile']
            result = key['Result']

            search_team = dict(key['Teams'])

            for x, y in search_team.items():
                if team.lower() in x.lower():
                    saved_results.append("Â· **{}** to [**{}**] is/was: **{}**".format(first_name, prediction, result))

        output_str = ""
        i = 1

        # Discord errors out if character limit exceeds 2,000
        for player in saved_results:
            if i > 10:
                break
            i += 1

            output_str += "{}\n".format(player)

        embed = discord.Embed(title=" ", color=0xff0000)
        embed.set_author(name="HuskerBot")
        embed.add_field(name="Crystal Ball Search Results for {}".format(team), value=output_str, inline=False)
        await ctx.send(embed=embed)

    # TODO Instead of adding a new message after clicking a search result...edit the search result message.
    @commands.command(aliases=["cb", ])
    @commands.cooldown(rate=globalRate, per=globalPer, type=commands.BucketType.user)
    async def crootbot(self, ctx, year, *name):
        """ CrootBot provides the ability to search for and return information on football recruits. Usage is `$crootbot <year> <first_name> <last_name>`. The command is able to find partial first and last names. """
        # pulls a json file from the 247 advanced player search API and parses it to give info on the croot.
        # First, pull the message content, split the individual pieces, and make the api call

        # This keeps bot spam down to a minimal.
        # await function_helper.check_command_channel(ctx.command, ctx.channel)
        #         # if not function_helper.correct_channel:
        #         #     await ctx.send(wrong_channel_text)
        #         #     return

        if len(name) == 2:
            url = 'https://247sports.com/Season/{}-Football/Recruits.json?&Items=15&Page=1&Player.FirstName={}&Player.LastName={}'.format(year, name[0], name[1])
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'}
            search = requests.get(url=url, headers=headers)
            search = json.loads(search.text)
        elif len(name) == 1:
            url_first = 'https://247sports.com/Season/{}-Football/Recruits.json?&Items=15&Page=1&Player.FirstName={}'.format(year, name[0])
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'}
            search_first = requests.get(url=url_first, headers=headers)
            search_first = json.loads(search_first.text)

            url_last = 'https://247sports.com/Season/{}-Football/Recruits.json?&Items=15&Page=1&Player.LastName={}'.format(year, name[0])
            search_last = requests.get(url=url_last, headers=headers)
            search_last = json.loads(search_last.text)

            search = search_first + search_last
        else:
            await ctx.send("You need to provide a year and name for me to search. I accept queries in the format $crootbot <year><name>.")
            return

        if not search:
            if len(name) == 1:
                await ctx.send("I could not find any player named {} in the {} class".format(name[0], year))
            elif len(name) == 2:
                await ctx.send("I could not find any player named {} {} in the {} class".format(name[0], name[1], year))
        elif len(search) > 1:
            # global player_search_list
            # players_string='Mulitple results found for **[{}, {} {}]**. React with the corresponding emoji for CrootBot results.\n__**Search Results:**__\n'.format(year, first_name, last_name)
            players_string = ''
            players_list = []
            config.player_search_list = search
            for i in range(min(10, len(search))):
                player = search[i]['Player']
                first_name = player['FirstName']
                last_name = player['LastName']
                position = player['PrimaryPlayerPosition']['Abbreviation']
                if position in long_positions:
                    position = long_positions[position]
                players_string += '{}: {} {} - {}\n'.format(emoji_list[i], first_name, last_name, position)
                players_list.append(['FirstName', 'LastName'])

            # Embed stuff
            result_text = ''
            if len(name) == 2:
                result_text = 'Mulitple results found for __**[{}, {} {}]**__. React with the corresponding emoji for CrootBot results.\n\n'.format(year, name[0], name[1])
            elif len(name) == 1:
                result_text = 'Mulitple results found for __**[{}, {}]**__. React with the corresponding emoji for CrootBot results.\n\n'.format(year, name[0])

            embed_text = result_text + players_string
            embed = discord.Embed(title="Search Results", description=embed_text, color=0xff0000)
            embed.set_author(name="HuskerBot CrootBot")
            embed.set_footer(text='Search Results ' + huskerbot_footer)
            await ctx.send(embed=embed)
        else:
            channel = ctx.channel
            await parse_search(search[0], channel)  # The json that is returned is a list of dictionaries, I pull the first item in the list (may consider adding complexity)


def setup(bot):
    bot.add_cog(CrootBot(bot))
